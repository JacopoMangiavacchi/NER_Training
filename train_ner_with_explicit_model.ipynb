{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_ner.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "nlp_eval",
      "language": "python",
      "name": "nlp_eval"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1155c73cd824e22862fa55c544949a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1ed4b55bfd54aeba826d915916afac5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d30d96babef4f9781f9acc0acf31d43",
              "IPY_MODEL_9fdfaaebc2444990a329fd770f7b79ca"
            ]
          }
        },
        "f1ed4b55bfd54aeba826d915916afac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d30d96babef4f9781f9acc0acf31d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7efd7c27a0b3447db842a7ee9d76d124",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbb1f9bd8d1440c09e8a2f35ef882047"
          }
        },
        "9fdfaaebc2444990a329fd770f7b79ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2888a4136079498e9dbd9fd85418ee84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 398kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5acd6e4baaf14034895a76f23d7d363a"
          }
        },
        "7efd7c27a0b3447db842a7ee9d76d124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbb1f9bd8d1440c09e8a2f35ef882047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2888a4136079498e9dbd9fd85418ee84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5acd6e4baaf14034895a76f23d7d363a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "414ae6dc300d4c8ca7e26b015a4f0c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a7ddd6e3c7b47ccafdc3483963a4e46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8fa4444493c4212916efc8c1f4a7c9a",
              "IPY_MODEL_468591d283f043278c322f1f4cdce854"
            ]
          }
        },
        "2a7ddd6e3c7b47ccafdc3483963a4e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8fa4444493c4212916efc8c1f4a7c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7d88baf400045738054233cefaff7e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9edf9b15f90c4194ab39394bc2511cc1"
          }
        },
        "468591d283f043278c322f1f4cdce854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9c3a38118af46b4851bfbe67349b76a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 1.33MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08839903c6eb4ae1aab355117529f880"
          }
        },
        "c7d88baf400045738054233cefaff7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9edf9b15f90c4194ab39394bc2511cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9c3a38118af46b4851bfbe67349b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08839903c6eb4ae1aab355117529f880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoMangiavacchi/NER_Training/blob/main/train_ner_with_explicit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR14T8v84PNx"
      },
      "source": [
        "PRE_TRAINED_BERT_MODEL = 'distilbert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D37tgrEVtyZ5"
      },
      "source": [
        "# Basic Transformers class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByoHEM0Rt-hZ"
      },
      "source": [
        "# Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" PyTorch DistilBERT model\n",
        "    adapted in part from Facebook, Inc XLM model (https://github.com/facebookresearch/XLM)\n",
        "    and in part from HuggingFace PyTorch version of Google AI Bert model (https://github.com/google-research/bert)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import copy\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from activations import gelu\n",
        "from configuration_distilbert import DistilBertConfig\n",
        "from modeling_outputs import (\n",
        "    BaseModelOutput,\n",
        "    MaskedLMOutput,\n",
        "    MultipleChoiceModelOutput,\n",
        "    QuestionAnsweringModelOutput,\n",
        "    SequenceClassifierOutput,\n",
        "    TokenClassifierOutput,\n",
        ")\n",
        "import modeling_utils\n",
        "# from modeling_utils import (\n",
        "#     PreTrainedModel,\n",
        "#     apply_chunking_to_forward,\n",
        "#     find_pruneable_heads_and_indices,\n",
        "#     prune_linear_layer,\n",
        "# )\n",
        "from utils import logging\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "_CONFIG_FOR_DOC = \"DistilBertConfig\"\n",
        "_TOKENIZER_FOR_DOC = \"DistilBertTokenizer\"\n",
        "\n",
        "DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "    \"distilbert-base-uncased\",\n",
        "    \"distilbert-base-uncased-distilled-squad\",\n",
        "    \"distilbert-base-cased\",\n",
        "    \"distilbert-base-cased-distilled-squad\",\n",
        "    \"distilbert-base-german-cased\",\n",
        "    \"distilbert-base-multilingual-cased\",\n",
        "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    # See all DistilBERT models at https://huggingface.co/models?filter=distilbert\n",
        "]\n",
        "\n",
        "\n",
        "# UTILS AND BUILDING BLOCKS OF THE ARCHITECTURE #\n",
        "\n",
        "\n",
        "def create_sinusoidal_embeddings(n_pos, dim, out):\n",
        "    position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)])\n",
        "    out[:, 0::2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n",
        "    out[:, 1::2] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n",
        "    out.detach_()\n",
        "    out.requires_grad = False\n",
        "\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.dim, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.dim)\n",
        "        if config.sinusoidal_pos_embds:\n",
        "            create_sinusoidal_embeddings(\n",
        "                n_pos=config.max_position_embeddings, dim=config.dim, out=self.position_embeddings.weight\n",
        "            )\n",
        "\n",
        "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_ids: torch.tensor(bs, max_seq_length)\n",
        "            The token ids to embed.\n",
        "\n",
        "        Outputs\n",
        "        -------\n",
        "        embeddings: torch.tensor(bs, max_seq_length, dim)\n",
        "            The embedded tokens (plus position embeddings, no token_type embeddings)\n",
        "        \"\"\"\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # (max_seq_length)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (bs, max_seq_length)\n",
        "\n",
        "        word_embeddings = self.word_embeddings(input_ids)  # (bs, max_seq_length, dim)\n",
        "        position_embeddings = self.position_embeddings(position_ids)  # (bs, max_seq_length, dim)\n",
        "\n",
        "        embeddings = word_embeddings + position_embeddings  # (bs, max_seq_length, dim)\n",
        "        embeddings = self.LayerNorm(embeddings)  # (bs, max_seq_length, dim)\n",
        "        embeddings = self.dropout(embeddings)  # (bs, max_seq_length, dim)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_heads = config.n_heads\n",
        "        self.dim = config.dim\n",
        "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
        "\n",
        "        assert self.dim % self.n_heads == 0\n",
        "\n",
        "        self.q_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.k_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.v_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.out_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        attention_head_size = self.dim // self.n_heads\n",
        "        if len(heads) == 0:\n",
        "            return\n",
        "        heads, index = find_pruneable_heads_and_indices(heads, self.n_heads, attention_head_size, self.pruned_heads)\n",
        "        # Prune linear layers\n",
        "        self.q_lin = prune_linear_layer(self.q_lin, index)\n",
        "        self.k_lin = prune_linear_layer(self.k_lin, index)\n",
        "        self.v_lin = prune_linear_layer(self.v_lin, index)\n",
        "        self.out_lin = prune_linear_layer(self.out_lin, index, dim=1)\n",
        "        # Update hyper params\n",
        "        self.n_heads = self.n_heads - len(heads)\n",
        "        self.dim = attention_head_size * self.n_heads\n",
        "        self.pruned_heads = self.pruned_heads.union(heads)\n",
        "\n",
        "    def forward(self, query, key, value, mask, head_mask=None, output_attentions=False):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        query: torch.tensor(bs, seq_length, dim)\n",
        "        key: torch.tensor(bs, seq_length, dim)\n",
        "        value: torch.tensor(bs, seq_length, dim)\n",
        "        mask: torch.tensor(bs, seq_length)\n",
        "\n",
        "        Outputs\n",
        "        -------\n",
        "        weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n",
        "            Attention weights\n",
        "        context: torch.tensor(bs, seq_length, dim)\n",
        "            Contextualized layer. Optional: only if `output_attentions=True`\n",
        "        \"\"\"\n",
        "        bs, q_length, dim = query.size()\n",
        "        k_length = key.size(1)\n",
        "        # assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)\n",
        "        # assert key.size() == value.size()\n",
        "\n",
        "        dim_per_head = self.dim // self.n_heads\n",
        "\n",
        "        mask_reshp = (bs, 1, 1, k_length)\n",
        "\n",
        "        def shape(x):\n",
        "            \"\"\" separate heads \"\"\"\n",
        "            return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
        "\n",
        "        def unshape(x):\n",
        "            \"\"\" group heads \"\"\"\n",
        "            return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
        "\n",
        "        q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
        "        k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
        "        v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
        "\n",
        "        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
        "        mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
        "        scores.masked_fill_(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)\n",
        "\n",
        "        weights = nn.Softmax(dim=-1)(scores)  # (bs, n_heads, q_length, k_length)\n",
        "        weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            weights = weights * head_mask\n",
        "\n",
        "        context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        context = unshape(context)  # (bs, q_length, dim)\n",
        "        context = self.out_lin(context)  # (bs, q_length, dim)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context, weights)\n",
        "        else:\n",
        "            return (context,)\n",
        "\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        self.seq_len_dim = 1\n",
        "        self.lin1 = nn.Linear(in_features=config.dim, out_features=config.hidden_dim)\n",
        "        self.lin2 = nn.Linear(in_features=config.hidden_dim, out_features=config.dim)\n",
        "        assert config.activation in [\"relu\", \"gelu\"], \"activation ({}) must be in ['relu', 'gelu']\".format(\n",
        "            config.activation\n",
        "        )\n",
        "        self.activation = gelu if config.activation == \"gelu\" else nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)\n",
        "\n",
        "    def ff_chunk(self, input):\n",
        "        x = self.lin1(input)\n",
        "        x = self.activation(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        assert config.dim % config.n_heads == 0\n",
        "\n",
        "        self.attention = MultiHeadSelfAttention(config)\n",
        "        self.sa_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
        "\n",
        "        self.ffn = FFN(config)\n",
        "        self.output_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
        "\n",
        "    def forward(self, x, attn_mask=None, head_mask=None, output_attentions=False):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: torch.tensor(bs, seq_length, dim)\n",
        "        attn_mask: torch.tensor(bs, seq_length)\n",
        "\n",
        "        Outputs\n",
        "        -------\n",
        "        sa_weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n",
        "            The attention weights\n",
        "        ffn_output: torch.tensor(bs, seq_length, dim)\n",
        "            The output of the transformer block contextualization.\n",
        "        \"\"\"\n",
        "        # Self-Attention\n",
        "        sa_output = self.attention(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            mask=attn_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        if output_attentions:\n",
        "            sa_output, sa_weights = sa_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
        "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
        "            assert type(sa_output) == tuple\n",
        "            sa_output = sa_output[0]\n",
        "        sa_output = self.sa_layer_norm(sa_output + x)  # (bs, seq_length, dim)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)\n",
        "        ffn_output = self.output_layer_norm(ffn_output + sa_output)  # (bs, seq_length, dim)\n",
        "\n",
        "        output = (ffn_output,)\n",
        "        if output_attentions:\n",
        "            output = (sa_weights,) + output\n",
        "        return output\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_layers = config.n_layers\n",
        "\n",
        "        layer = TransformerBlock(config)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.n_layers)])\n",
        "\n",
        "    def forward(\n",
        "        self, x, attn_mask=None, head_mask=None, output_attentions=False, output_hidden_states=False, return_dict=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: torch.tensor(bs, seq_length, dim)\n",
        "            Input sequence embedded.\n",
        "        attn_mask: torch.tensor(bs, seq_length)\n",
        "            Attention mask on the sequence.\n",
        "\n",
        "        Outputs\n",
        "        -------\n",
        "        hidden_state: torch.tensor(bs, seq_length, dim)\n",
        "            Sequence of hiddens states in the last (top) layer\n",
        "        all_hidden_states: Tuple[torch.tensor(bs, seq_length, dim)]\n",
        "            Tuple of length n_layers with the hidden states from each layer.\n",
        "            Optional: only if output_hidden_states=True\n",
        "        all_attentions: Tuple[torch.tensor(bs, n_heads, seq_length, seq_length)]\n",
        "            Tuple of length n_layers with the attention weights from each layer\n",
        "            Optional: only if output_attentions=True\n",
        "        \"\"\"\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        hidden_state = x\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_state,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                x=hidden_state, attn_mask=attn_mask, head_mask=head_mask[i], output_attentions=output_attentions\n",
        "            )\n",
        "            hidden_state = layer_outputs[-1]\n",
        "\n",
        "            if output_attentions:\n",
        "                assert len(layer_outputs) == 2\n",
        "                attentions = layer_outputs[0]\n",
        "                all_attentions = all_attentions + (attentions,)\n",
        "            else:\n",
        "                assert len(layer_outputs) == 1\n",
        "\n",
        "        # Add last layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_state,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_state, all_hidden_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_state, hidden_states=all_hidden_states, attentions=all_attentions\n",
        "        )\n",
        "\n",
        "\n",
        "class PreTrainedModel:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        requires_pytorch(self)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(self, *args, **kwargs):\n",
        "        requires_pytorch(self)\n",
        "    \n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0QxY_xYt9ij"
      },
      "source": [
        "# Distilbert basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc4GWyLpuEPO"
      },
      "source": [
        "# INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n",
        "class DistilBertPreTrainedModel(PreTrainedModel):\n",
        "    \"\"\"An abstract class to handle weights initialization and\n",
        "    a simple interface for downloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "\n",
        "    config_class = DistilBertConfig\n",
        "    load_tf_weights = None\n",
        "    base_model_prefix = \"distilbert\"\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"Initialize the weights.\"\"\"\n",
        "        if isinstance(module, nn.Embedding):\n",
        "            if module.weight.requires_grad:\n",
        "                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "\n",
        "DISTILBERT_START_DOCSTRING = r\"\"\"\n",
        "\n",
        "    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n",
        "    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n",
        "    pruning heads etc.)\n",
        "\n",
        "    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass.\n",
        "    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general\n",
        "    usage and behavior.\n",
        "\n",
        "    Parameters:\n",
        "        config (:class:`~transformers.DistilBertConfig`): Model configuration class with all the parameters of the model.\n",
        "            Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
        "            Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n",
        "\"\"\"\n",
        "\n",
        "DISTILBERT_INPUTS_DOCSTRING = r\"\"\"\n",
        "    Args:\n",
        "        input_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`):\n",
        "            Indices of input sequence tokens in the vocabulary.\n",
        "\n",
        "            Indices can be obtained using :class:`~transformers.DistilBertTokenizer`.\n",
        "            See :meth:`transformers.PreTrainedTokenizer.encode` and\n",
        "            :meth:`transformers.PreTrainedTokenizer.__call__` for details.\n",
        "\n",
        "            `What are input IDs? <../glossary.html#input-ids>`__\n",
        "        attention_mask (:obj:`torch.FloatTensor` of shape :obj:`({0})`, `optional`):\n",
        "            Mask to avoid performing attention on padding token indices.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "\n",
        "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
        "        head_mask (:obj:`torch.FloatTensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\n",
        "            Mask to nullify selected heads of the self-attention modules.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`({0}, hidden_size)`, `optional`):\n",
        "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
        "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\n",
        "            vectors than the model's internal embedding lookup matrix.\n",
        "        output_attentions (:obj:`bool`, `optional`):\n",
        "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n",
        "            tensors for more detail.\n",
        "        output_hidden_states (:obj:`bool`, `optional`):\n",
        "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n",
        "            more detail.\n",
        "        return_dict (:obj:`bool`, `optional`):\n",
        "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DistilBertModel(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.embeddings = Embeddings(config)  # Embeddings\n",
        "        self.transformer = Transformer(config)  # Encoder\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embeddings.word_embeddings\n",
        "\n",
        "    def set_input_embeddings(self, new_embeddings):\n",
        "        self.embeddings.word_embeddings = new_embeddings\n",
        "\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"Prunes heads of the model.\n",
        "        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
        "        See base class PreTrainedModel\n",
        "        \"\"\"\n",
        "        for layer, heads in heads_to_prune.items():\n",
        "            self.transformer.layer[layer].attention.prune_heads(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embeddings(input_ids)  # (bs, seq_length, dim)\n",
        "        return self.transformer(\n",
        "            x=inputs_embeds,\n",
        "            attn_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsoRPO8puE3r"
      },
      "source": [
        "# Distilbert For Token Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4HOHERJtyZ7"
      },
      "source": [
        "class DistilBertForTokenClassification(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
        "            Labels for computing the token classification loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.distilbert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            # Only keep active parts of the loss\n",
        "            if attention_mask is not None:\n",
        "                active_loss = attention_mask.view(-1) == 1\n",
        "                active_logits = logits.view(-1, self.num_labels)\n",
        "                active_labels = torch.where(\n",
        "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "                )\n",
        "                loss = loss_fct(active_logits, active_labels)\n",
        "            else:\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return TokenClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9N4MbV30FYF"
      },
      "source": [
        "# Get Distilbert for Token Classification model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PM6Bqv90Ewu",
        "outputId": "8bbf33a1-cfc0-43b5-8bf1-2de5accb6ec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from transformers import DistilBertForTokenClassification\n",
        "\n",
        "unique_tags = {'B-problem',\n",
        "  'B-test',\n",
        "  'B-treatment',\n",
        "  'I-problem',\n",
        "  'I-test',\n",
        "  'I-treatment',\n",
        "  'O'}\n",
        "\n",
        "model = DistilBertForTokenClassification.from_pretrained(PRE_TRAINED_BERT_MODEL, num_labels=len(unique_tags))\n",
        "\n",
        "torch.save(model.state_dict(), PRE_TRAINED_BERT_MODEL + '_weight.pth')\n",
        "\n",
        "del model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AjNHs58ECv0"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ1y8VlSEECn",
        "outputId": "86ff875e-f1e8-422c-db6a-dbaf879f0f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vcwgb4LECv2",
        "outputId": "0bb80445-d04e-4c3e-a94f-90cb0a08e89c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://noisy-text.github.io/2017/files/wnut17train.conll"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-04 20:08:01--  http://noisy-text.github.io/2017/files/wnut17train.conll\n",
            "Resolving noisy-text.github.io (noisy-text.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to noisy-text.github.io (noisy-text.github.io)|185.199.108.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 493781 (482K) [application/octet-stream]\n",
            "Saving to: â€˜wnut17train.conllâ€™\n",
            "\n",
            "\rwnut17train.conll     0%[                    ]       0  --.-KB/s               \rwnut17train.conll   100%[===================>] 482.21K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-04 20:08:01 (15.0 MB/s) - â€˜wnut17train.conllâ€™ saved [493781/493781]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl2WEc8zECv8"
      },
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_wnut(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            token, tag = line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "texts, tags = read_wnut('wnut17train.conll')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnoh5HmECwA",
        "outputId": "a3d6e021-3568-4138-ff8c-ed60e4b04c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(set([str(t) for line in tags for t in line]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-creative-work',\n",
              " 'B-person',\n",
              " 'I-product',\n",
              " 'B-product',\n",
              " 'B-creative-work',\n",
              " 'O',\n",
              " 'I-group',\n",
              " 'I-location',\n",
              " 'I-person',\n",
              " 'B-corporation',\n",
              " 'B-location',\n",
              " 'I-corporation',\n",
              " 'B-group']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVoSsOIECwE",
        "outputId": "0aaaacb3-46a4-4102-8c82-630bd724033d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(texts[0][10:17], tags[0][10:17], sep='\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['for', 'two', 'weeks', '.', 'Empire', 'State', 'Building']\n",
            "['O', 'O', 'O', 'O', 'B-location', 'I-location', 'I-location']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoTr96XeECwG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13IwtJzECwJ",
        "outputId": "7c99b2d3-b43c-4bc6-f05a-b58cf3c04b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_texts), len(val_texts)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2715, 679)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUwIwdr8ECwM"
      },
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs44h6xyECwO",
        "outputId": "8310af84-024e-4636-d410-fefba6eb7983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "id2tag"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'I-creative-work',\n",
              " 1: 'B-person',\n",
              " 2: 'I-product',\n",
              " 3: 'B-product',\n",
              " 4: 'B-creative-work',\n",
              " 5: 'O',\n",
              " 6: 'I-group',\n",
              " 7: 'I-location',\n",
              " 8: 'I-person',\n",
              " 9: 'B-corporation',\n",
              " 10: 'B-location',\n",
              " 11: 'I-corporation',\n",
              " 12: 'B-group'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2jIJICiECwQ"
      },
      "source": [
        "# Use pre-trained DistilBert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxgof0hcECwQ",
        "outputId": "e9131756-592e-4a73-9389-648418a56e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c1155c73cd824e22862fa55c544949a9",
            "f1ed4b55bfd54aeba826d915916afac5",
            "4d30d96babef4f9781f9acc0acf31d43",
            "9fdfaaebc2444990a329fd770f7b79ca",
            "7efd7c27a0b3447db842a7ee9d76d124",
            "bbb1f9bd8d1440c09e8a2f35ef882047",
            "2888a4136079498e9dbd9fd85418ee84",
            "5acd6e4baaf14034895a76f23d7d363a",
            "414ae6dc300d4c8ca7e26b015a4f0c67",
            "2a7ddd6e3c7b47ccafdc3483963a4e46",
            "d8fa4444493c4212916efc8c1f4a7c9a",
            "468591d283f043278c322f1f4cdce854",
            "c7d88baf400045738054233cefaff7e2",
            "9edf9b15f90c4194ab39394bc2511cc1",
            "b9c3a38118af46b4851bfbe67349b76a",
            "08839903c6eb4ae1aab355117529f880"
          ]
        }
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(PRE_TRAINED_BERT_MODEL)\n",
        "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1155c73cd824e22862fa55c544949a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "414ae6dc300d4c8ca7e26b015a4f0c67",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SzEbadHECwS",
        "outputId": "325bbdd8-a64e-4257-edbc-9d7a69b8ea33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIAibb_vECwU",
        "outputId": "e35f61af-6897-42f5-d46f-3ab7cc68f2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_encodings['input_ids']), len(val_encodings['input_ids'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2715, 679)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dax_NmvvECwW",
        "outputId": "d758c6a0-3883-4629-ce1b-a118c5437341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_encodings['input_ids'][0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FxJ8bDnECwZ"
      },
      "source": [
        "# Format labels for sub token splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMIN-NmWECwZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "        arr_offset = np.array(doc_offset)\n",
        "\n",
        "        # set labels whose first offset position is 0 and the second is not 0\n",
        "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels\n",
        "\n",
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VED-SYcGECwb",
        "outputId": "7322f83a-fc66-4d3e-eb4b-7bff0cd47114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_labels), len(val_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2715, 679)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWJULml-ECwd",
        "outputId": "73b9927f-0033-4715-a547-7ac4458d89ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_labels[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii3Bm9jBECwf"
      },
      "source": [
        "# Create Dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i67IxZZXECwf"
      },
      "source": [
        "import torch\n",
        "\n",
        "class WNUTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset = WNUTDataset(train_encodings, train_labels)\n",
        "val_dataset = WNUTDataset(val_encodings, val_labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OSGqeUW0zOf"
      },
      "source": [
        "# Instantiate Model from PyTorch class module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlIDyx83Bry"
      },
      "source": [
        "from transformers import BertConfig\n",
        "config = BertConfig.from_pretrained(PRE_TRAINED_BERT_MODEL) "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2E7erXs0zAp"
      },
      "source": [
        "model = DistilBertForTokenClassification(config)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A55ZRJlO1AfL"
      },
      "source": [
        "# Load Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7t8eZj61Ast"
      },
      "source": [
        "weight = torch.load(PRE_TRAINED_BERT_MODEL + '_weight.pth', map_location='cpu')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6MVFucy2Bar",
        "outputId": "5f074cdb-65b4-4ae3-c583-e5b86276dbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "model.load_state_dict(weight)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-0181ed2ec77e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DistilBertForTokenClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2])."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE_Xz_HaECwk"
      },
      "source": [
        "# Fine Tune DistilBert using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEqQDeUUECwk"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model2.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    epoch_loss = 0.0\n",
        "    num_batch = 0\n",
        "    for i, batch in enumerate(train_loader, 0):\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model2(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #print(f\"Epoch {epoch} Batch {i} : Loss {loss.data}\")\n",
        "        epoch_loss += loss.item()\n",
        "        num_batch += 1\n",
        "    print(f\"Epoch {epoch} : Loss {epoch_loss / num_batch}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p5_zvu5ECwm"
      },
      "source": [
        "model2.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDb-iNphECwn"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH2-QCiPECwp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}