{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JacopoMangiavacchi/NER_Training/blob/main/train_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get DistilBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'add_start_docstrings_to_callable' from 'file_utils' (/Users/jacopo/sources/personal/NER_Training/file_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9838c03804c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfiguration_distilbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistilBertConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m from file_utils import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0madd_code_sample_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0madd_start_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'add_start_docstrings_to_callable' from 'file_utils' (/Users/jacopo/sources/personal/NER_Training/file_utils.py)"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\" PyTorch DistilBERT model\n",
    "    adapted in part from Facebook, Inc XLM model (https://github.com/facebookresearch/XLM)\n",
    "    and in part from HuggingFace PyTorch version of Google AI Bert model (https://github.com/google-research/bert)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from activations import gelu\n",
    "from configuration_distilbert import DistilBertConfig\n",
    "from file_utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_callable,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from modeling_outputs import (\n",
    "    BaseModelOutput,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from modeling_utils import (\n",
    "    PreTrainedModel,\n",
    "    apply_chunking_to_forward,\n",
    "    find_pruneable_heads_and_indices,\n",
    "    prune_linear_layer,\n",
    ")\n",
    "from utils import logging\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CONFIG_FOR_DOC = \"DistilBertConfig\"\n",
    "_TOKENIZER_FOR_DOC = \"DistilBertTokenizer\"\n",
    "\n",
    "DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    \"distilbert-base-cased\",\n",
    "    \"distilbert-base-cased-distilled-squad\",\n",
    "    \"distilbert-base-german-cased\",\n",
    "    \"distilbert-base-multilingual-cased\",\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    # See all DistilBERT models at https://huggingface.co/models?filter=distilbert\n",
    "]\n",
    "\n",
    "\n",
    "# UTILS AND BUILDING BLOCKS OF THE ARCHITECTURE #\n",
    "\n",
    "\n",
    "def create_sinusoidal_embeddings(n_pos, dim, out):\n",
    "    position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)])\n",
    "    out[:, 0::2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n",
    "    out[:, 1::2] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n",
    "    out.detach_()\n",
    "    out.requires_grad = False\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.dim, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.dim)\n",
    "        if config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=config.max_position_embeddings, dim=config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids: torch.tensor(bs, max_seq_length)\n",
    "            The token ids to embed.\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        embeddings: torch.tensor(bs, max_seq_length, dim)\n",
    "            The embedded tokens (plus position embeddings, no token_type embeddings)\n",
    "        \"\"\"\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # (max_seq_length)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (bs, max_seq_length)\n",
    "\n",
    "        word_embeddings = self.word_embeddings(input_ids)  # (bs, max_seq_length, dim)\n",
    "        position_embeddings = self.position_embeddings(position_ids)  # (bs, max_seq_length, dim)\n",
    "\n",
    "        embeddings = word_embeddings + position_embeddings  # (bs, max_seq_length, dim)\n",
    "        embeddings = self.LayerNorm(embeddings)  # (bs, max_seq_length, dim)\n",
    "        embeddings = self.dropout(embeddings)  # (bs, max_seq_length, dim)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = config.n_heads\n",
    "        self.dim = config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        assert self.dim % self.n_heads == 0\n",
    "\n",
    "        self.q_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.out_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        attention_head_size = self.dim // self.n_heads\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.n_heads, attention_head_size, self.pruned_heads)\n",
    "        # Prune linear layers\n",
    "        self.q_lin = prune_linear_layer(self.q_lin, index)\n",
    "        self.k_lin = prune_linear_layer(self.k_lin, index)\n",
    "        self.v_lin = prune_linear_layer(self.v_lin, index)\n",
    "        self.out_lin = prune_linear_layer(self.out_lin, index, dim=1)\n",
    "        # Update hyper params\n",
    "        self.n_heads = self.n_heads - len(heads)\n",
    "        self.dim = attention_head_size * self.n_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(self, query, key, value, mask, head_mask=None, output_attentions=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: torch.tensor(bs, seq_length, dim)\n",
    "        key: torch.tensor(bs, seq_length, dim)\n",
    "        value: torch.tensor(bs, seq_length, dim)\n",
    "        mask: torch.tensor(bs, seq_length)\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n",
    "            Attention weights\n",
    "        context: torch.tensor(bs, seq_length, dim)\n",
    "            Contextualized layer. Optional: only if `output_attentions=True`\n",
    "        \"\"\"\n",
    "        bs, q_length, dim = query.size()\n",
    "        k_length = key.size(1)\n",
    "        # assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)\n",
    "        # assert key.size() == value.size()\n",
    "\n",
    "        dim_per_head = self.dim // self.n_heads\n",
    "\n",
    "        mask_reshp = (bs, 1, 1, k_length)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\" separate heads \"\"\"\n",
    "            return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\" group heads \"\"\"\n",
    "            return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
    "\n",
    "        q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
    "        k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
    "        v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
    "\n",
    "        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
    "        mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
    "        scores.masked_fill_(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        weights = nn.Softmax(dim=-1)(scores)  # (bs, n_heads, q_length, k_length)\n",
    "        weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            weights = weights * head_mask\n",
    "\n",
    "        context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        context = unshape(context)  # (bs, q_length, dim)\n",
    "        context = self.out_lin(context)  # (bs, q_length, dim)\n",
    "\n",
    "        if output_attentions:\n",
    "            return (context, weights)\n",
    "        else:\n",
    "            return (context,)\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=config.dropout)\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.lin1 = nn.Linear(in_features=config.dim, out_features=config.hidden_dim)\n",
    "        self.lin2 = nn.Linear(in_features=config.hidden_dim, out_features=config.dim)\n",
    "        assert config.activation in [\"relu\", \"gelu\"], \"activation ({}) must be in ['relu', 'gelu']\".format(\n",
    "            config.activation\n",
    "        )\n",
    "        self.activation = gelu if config.activation == \"gelu\" else nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)\n",
    "\n",
    "    def ff_chunk(self, input):\n",
    "        x = self.lin1(input)\n",
    "        x = self.activation(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        assert config.dim % config.n_heads == 0\n",
    "\n",
    "        self.attention = MultiHeadSelfAttention(config)\n",
    "        self.sa_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
    "\n",
    "        self.ffn = FFN(config)\n",
    "        self.output_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
    "\n",
    "    def forward(self, x, attn_mask=None, head_mask=None, output_attentions=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.tensor(bs, seq_length, dim)\n",
    "        attn_mask: torch.tensor(bs, seq_length)\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        sa_weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n",
    "            The attention weights\n",
    "        ffn_output: torch.tensor(bs, seq_length, dim)\n",
    "            The output of the transformer block contextualization.\n",
    "        \"\"\"\n",
    "        # Self-Attention\n",
    "        sa_output = self.attention(\n",
    "            query=x,\n",
    "            key=x,\n",
    "            value=x,\n",
    "            mask=attn_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        if output_attentions:\n",
    "            sa_output, sa_weights = sa_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
    "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
    "            assert type(sa_output) == tuple\n",
    "            sa_output = sa_output[0]\n",
    "        sa_output = self.sa_layer_norm(sa_output + x)  # (bs, seq_length, dim)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)\n",
    "        ffn_output = self.output_layer_norm(ffn_output + sa_output)  # (bs, seq_length, dim)\n",
    "\n",
    "        output = (ffn_output,)\n",
    "        if output_attentions:\n",
    "            output = (sa_weights,) + output\n",
    "        return output\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_layers = config.n_layers\n",
    "\n",
    "        layer = TransformerBlock(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.n_layers)])\n",
    "\n",
    "    def forward(\n",
    "        self, x, attn_mask=None, head_mask=None, output_attentions=False, output_hidden_states=False, return_dict=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.tensor(bs, seq_length, dim)\n",
    "            Input sequence embedded.\n",
    "        attn_mask: torch.tensor(bs, seq_length)\n",
    "            Attention mask on the sequence.\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        hidden_state: torch.tensor(bs, seq_length, dim)\n",
    "            Sequence of hiddens states in the last (top) layer\n",
    "        all_hidden_states: Tuple[torch.tensor(bs, seq_length, dim)]\n",
    "            Tuple of length n_layers with the hidden states from each layer.\n",
    "            Optional: only if output_hidden_states=True\n",
    "        all_attentions: Tuple[torch.tensor(bs, n_heads, seq_length, seq_length)]\n",
    "            Tuple of length n_layers with the attention weights from each layer\n",
    "            Optional: only if output_attentions=True\n",
    "        \"\"\"\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "\n",
    "        hidden_state = x\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                x=hidden_state, attn_mask=attn_mask, head_mask=head_mask[i], output_attentions=output_attentions\n",
    "            )\n",
    "            hidden_state = layer_outputs[-1]\n",
    "\n",
    "            if output_attentions:\n",
    "                assert len(layer_outputs) == 2\n",
    "                attentions = layer_outputs[0]\n",
    "                all_attentions = all_attentions + (attentions,)\n",
    "            else:\n",
    "                assert len(layer_outputs) == 1\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_state, all_hidden_states, all_attentions] if v is not None)\n",
    "        return BaseModelOutput(\n",
    "            last_hidden_state=hidden_state, hidden_states=all_hidden_states, attentions=all_attentions\n",
    "        )\n",
    "\n",
    "\n",
    "# INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n",
    "class DistilBertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"An abstract class to handle weights initialization and\n",
    "    a simple interface for downloading and loading pretrained models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = DistilBertConfig\n",
    "    load_tf_weights = None\n",
    "    base_model_prefix = \"distilbert\"\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize the weights.\"\"\"\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            if module.weight.requires_grad:\n",
    "                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "\n",
    "DISTILBERT_START_DOCSTRING = r\"\"\"\n",
    "\n",
    "    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n",
    "    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n",
    "    pruning heads etc.)\n",
    "\n",
    "    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass.\n",
    "    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general\n",
    "    usage and behavior.\n",
    "\n",
    "    Parameters:\n",
    "        config (:class:`~transformers.DistilBertConfig`): Model configuration class with all the parameters of the model.\n",
    "            Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
    "            Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n",
    "\"\"\"\n",
    "\n",
    "DISTILBERT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using :class:`~transformers.DistilBertTokenizer`.\n",
    "            See :meth:`transformers.PreTrainedTokenizer.encode` and\n",
    "            :meth:`transformers.PreTrainedTokenizer.__call__` for details.\n",
    "\n",
    "            `What are input IDs? <../glossary.html#input-ids>`__\n",
    "        attention_mask (:obj:`torch.FloatTensor` of shape :obj:`({0})`, `optional`):\n",
    "            Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
    "        head_mask (:obj:`torch.FloatTensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\n",
    "            Mask to nullify selected heads of the self-attention modules.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`({0}, hidden_size)`, `optional`):\n",
    "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
    "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\n",
    "            vectors than the model's internal embedding lookup matrix.\n",
    "        output_attentions (:obj:`bool`, `optional`):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (:obj:`bool`, `optional`):\n",
    "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (:obj:`bool`, `optional`):\n",
    "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"The bare DistilBERT encoder/transformer outputting raw hidden-states without any specific head on top.\",\n",
    "    DISTILBERT_START_DOCSTRING,\n",
    ")\n",
    "class DistilBertModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embeddings = Embeddings(config)  # Embeddings\n",
    "        self.transformer = Transformer(config)  # Encoder\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.embeddings.word_embeddings = new_embeddings\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"Prunes heads of the model.\n",
    "        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "        See base class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.transformer.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_callable(DISTILBERT_INPUTS_DOCSTRING.format(\"batch_size, num_choices\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        tokenizer_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=\"distilbert-base-uncased\",\n",
    "        output_type=BaseModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    @add_code_sample_docstrings(tokenizer_class=_TOKENIZER_FOR_DOC, checkpoint=\"distilbert-base-uncased\")\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embeddings(input_ids)  # (bs, seq_length, dim)\n",
    "        return self.transformer(\n",
    "            x=inputs_embeds,\n",
    "            attn_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"DistilBert Model with a `masked language modeling` head on top. \"\"\",\n",
    "    DISTILBERT_START_DOCSTRING,\n",
    ")\n",
    "class DistilBertForMaskedLM(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.vocab_transform = nn.Linear(config.dim, config.dim)\n",
    "        self.vocab_layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.vocab_projector = nn.Linear(config.dim, config.vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.mlm_loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.vocab_projector\n",
    "\n",
    "    @add_start_docstrings_to_callable(DISTILBERT_INPUTS_DOCSTRING.format(\"batch_size, num_choices\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        tokenizer_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=\"distilbert-base-uncased\",\n",
    "        output_type=MaskedLMOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for computing the masked language modeling loss.\n",
    "            Indices should be in ``[-100, 0, ..., config.vocab_size]`` (see ``input_ids`` docstring)\n",
    "            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens with\n",
    "            labels in ``[0, ..., config.vocab_size]``.\n",
    "        kwargs (:obj:`Dict[str, any]`, optional, defaults to `{}`):\n",
    "            Used to hide legacy arguments that have been deprecated.\n",
    "        \"\"\"\n",
    "        if \"masked_lm_labels\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The `masked_lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n",
    "                FutureWarning,\n",
    "            )\n",
    "            labels = kwargs.pop(\"masked_lm_labels\")\n",
    "        assert kwargs == {}, f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        dlbrt_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = dlbrt_output[0]  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_transform(hidden_states)  # (bs, seq_length, dim)\n",
    "        prediction_logits = gelu(prediction_logits)  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_layer_norm(prediction_logits)  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_projector(prediction_logits)  # (bs, seq_length, vocab_size)\n",
    "\n",
    "        mlm_loss = None\n",
    "        if labels is not None:\n",
    "            mlm_loss = self.mlm_loss_fct(prediction_logits.view(-1, prediction_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_logits,) + dlbrt_output[1:]\n",
    "            return ((mlm_loss,) + output) if mlm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "            loss=mlm_loss,\n",
    "            logits=prediction_logits,\n",
    "            hidden_states=dlbrt_output.hidden_states,\n",
    "            attentions=dlbrt_output.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"DistilBert Model with a token classification head on top (a linear layer on top of\n",
    "    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. \"\"\",\n",
    "    DISTILBERT_START_DOCSTRING,\n",
    ")\n",
    "class DistilBertForTokenClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    @add_start_docstrings_to_callable(DISTILBERT_INPUTS_DOCSTRING)\n",
    "    @add_code_sample_docstrings(\n",
    "        tokenizer_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=\"distilbert-base-uncased\",\n",
    "        output_type=TokenClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for computing the token classification loss.\n",
    "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.distilbert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask is not None:\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)\n",
    "                active_labels = torch.where(\n",
    "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "                )\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AjNHs58ECv0"
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQ1y8VlSEECn",
    "outputId": "d316d3ec-0495-4486-ed8a-abeb9e8f5929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 4.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 29.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 29.4MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 41.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3de7e19db5d1c4b44020aa677f47cfa0faeb4231e42df0dc55430f8994ff2888\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vcwgb4LECv2",
    "outputId": "6f545af9-aa94-43ec-f3ef-c6f8495bbc5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-03 03:05:39--  http://noisy-text.github.io/2017/files/wnut17train.conll\n",
      "Resolving noisy-text.github.io (noisy-text.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to noisy-text.github.io (noisy-text.github.io)|185.199.108.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 493781 (482K) [application/octet-stream]\n",
      "Saving to: ‘wnut17train.conll.1’\n",
      "\n",
      "\r",
      "wnut17train.conll.1   0%[                    ]       0  --.-KB/s               \r",
      "wnut17train.conll.1 100%[===================>] 482.21K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-11-03 03:05:39 (11.9 MB/s) - ‘wnut17train.conll.1’ saved [493781/493781]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://noisy-text.github.io/2017/files/wnut17train.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl2WEc8zECv8"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def read_wnut(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'):\n",
    "            token, tag = line.split('\\t')\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "\n",
    "    return token_docs, tag_docs\n",
    "\n",
    "texts, tags = read_wnut('wnut17train.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsnoh5HmECwA",
    "outputId": "2a4c3e4e-6015-4a11-ff61-c4a7008331f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-creative-work',\n",
       " 'I-group',\n",
       " 'B-location',\n",
       " 'I-person',\n",
       " 'B-corporation',\n",
       " 'O',\n",
       " 'B-product',\n",
       " 'I-product',\n",
       " 'I-location',\n",
       " 'B-group',\n",
       " 'I-corporation',\n",
       " 'B-person',\n",
       " 'I-creative-work']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([str(t) for line in tags for t in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCVoSsOIECwE",
    "outputId": "352a67e0-947f-4102-da77-4f9944db94fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'two', 'weeks', '.', 'Empire', 'State', 'Building']\n",
      "['O', 'O', 'O', 'O', 'B-location', 'I-location', 'I-location']\n"
     ]
    }
   ],
   "source": [
    "print(texts[0][10:17], tags[0][10:17], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoTr96XeECwG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e13IwtJzECwJ",
    "outputId": "1164ed6e-698f-4221-cb4b-6ec458e1af5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2715, 679)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUwIwdr8ECwM"
   },
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in tags for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vs44h6xyECwO",
    "outputId": "228d6bed-f5d1-4fe3-dc57-a68c87f76bef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-creative-work',\n",
       " 1: 'I-group',\n",
       " 2: 'B-location',\n",
       " 3: 'I-person',\n",
       " 4: 'B-corporation',\n",
       " 5: 'O',\n",
       " 6: 'B-product',\n",
       " 7: 'I-product',\n",
       " 8: 'I-location',\n",
       " 9: 'B-group',\n",
       " 10: 'I-corporation',\n",
       " 11: 'B-person',\n",
       " 12: 'I-creative-work'}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2jIJICiECwQ"
   },
   "source": [
    "# Use pre-trained DistilBert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "943ba60c985f49538bfa6c76330140e4",
      "b01bc4d4e550497c8b75cfc38e2f55e6",
      "8e043b995e714da689e753ef23a11c6f",
      "47d1c50d45e342dda3048c70d11afe45",
      "5adb63bca7bd412b8c070e73c66dbd8c",
      "f97f95ed508e4650ac2a3a2196147c04",
      "4796ec72c743441c92432c168449e84d",
      "8863f4477a66419bbca96267727b90ac",
      "1d95e047c99b40d5b9ee01ab7f4300f6",
      "0eb683a2f2164631a40d023696d95aac",
      "080b8d2cfa924a499ee5de15d9179320",
      "56cfa0be0d1e4632a9820dd1ecbc7dca",
      "ebf45ae2922a4d5cb74de22823f5423a",
      "797b347816c3404dbb549bfcacb4a55b",
      "0b33d2c132a64a3aaf34fa71fc7cb21a",
      "10b4645f20ce448c8acef53935d26b03"
     ]
    },
    "id": "Oxgof0hcECwQ",
    "outputId": "829e70a0-6cf6-46e2-acc7-95dbb4fd8d79"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943ba60c985f49538bfa6c76330140e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d95e047c99b40d5b9ee01ab7f4300f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SzEbadHECwS",
    "outputId": "32e06c41-e2d2-458b-8921-fb4999bff9dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIAibb_vECwU",
    "outputId": "b8ceb64d-d6b1-42ab-e129-6731564cf06d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2715, 679)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings['input_ids']), len(val_encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dax_NmvvECwW",
    "outputId": "636eb69c-a21f-4859-fb71-718cba337259"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FxJ8bDnECwZ"
   },
   "source": [
    "# Format labels for sub token splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMIN-NmWECwZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_tags(tags, encodings):\n",
    "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "train_labels = encode_tags(train_tags, train_encodings)\n",
    "val_labels = encode_tags(val_tags, val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VED-SYcGECwb",
    "outputId": "c4b96565-f273-4ba9-b7e2-ba24032900b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2715, 679)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWJULml-ECwd",
    "outputId": "cba0e554-beb7-479c-a08b-9dd7103eac92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii3Bm9jBECwf"
   },
   "source": [
    "# Create Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i67IxZZXECwf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class WNUTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
    "val_encodings.pop(\"offset_mapping\")\n",
    "train_dataset = WNUTDataset(train_encodings, train_labels)\n",
    "val_dataset = WNUTDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kqfwq4JECwg"
   },
   "source": [
    "# Reuse DistilBert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "3382b33d766a493f890a833c24e76eea",
      "5059f3d33b0d40fba908f45480849872",
      "30d48ba25f504ed691a7db204334a7a2",
      "cd29ce07bda94c42b876a85f8f9a7bf6",
      "9a587da037ce4b27b76e5ca351638c3e",
      "7e6c6a620766468bb308e916d78e935f",
      "bc17fa0fbd5a4749a480f89892b0a6a7",
      "9fa47ad0b24a4740b930e3e6006553f1",
      "a0af086b308e410b9c63eba24cf559bb",
      "8b0aba7b184d4f68bf81bfaf1c3fe6ac",
      "b582ddba8d9d4c8a819884174e04fe20",
      "b15518e2992d4fa1969608da3d0f2ebd",
      "753efb968e0d42498fec98add09a64df",
      "3e9b557179ab417fb8f6ef4f25319d05",
      "d0cd7e971cd647aeae042ea8cfc289c1",
      "df72d4c8f06542c7bad9fefa1616dcb6"
     ]
    },
    "id": "9Y9z0nRjECwh",
    "outputId": "f68a05ca-fb1d-4cd0-9209-af8c869579b3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3382b33d766a493f890a833c24e76eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0af086b308e410b9c63eba24cf559bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForTokenClassification\n",
    "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhS3amFcECwi"
   },
   "source": [
    "# Option 1: Fine Tune DistilBert using HuggingFace Training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MMduTAOoECwi",
    "outputId": "bdd10b72-5411-4db3-fda1-4fcbb9f6d178"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [510/510 01:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.445358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.361238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.200238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.910114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.550927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.946352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.440773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.365919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.275309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.210490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.267378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.208627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.287344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.199033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.222415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.189043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.235376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.165518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.211949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.158505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.162259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.180418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.167764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.172821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.124429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.127945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.141382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.129980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.149995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.108313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.115562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.128764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.157246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.075075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.116864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.095805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.099142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.078172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.093579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.080101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.120992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.084274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.066852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.106551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.125107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.089922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.100827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.068553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=510, training_loss=0.3626458859911152)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE_Xz_HaECwk"
   },
   "source": [
    "# Option 2: Fine Tune DistilBert using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEqQDeUUECwk",
    "outputId": "aa419b13-a0c5-47af-a06f-704558b362ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss 0.28621605217237683\n",
      "Epoch 1 : Loss 0.1386249661226483\n",
      "Epoch 2 : Loss 0.07129617132903898\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Reload model as already trained in option 1\n",
    "model2 = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(unique_tags))\n",
    "model2.to(device)\n",
    "model2.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model2.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    epoch_loss = 0.0\n",
    "    num_batch = 0\n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model2(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #print(f\"Epoch {epoch} Batch {i} : Loss {loss.data}\")\n",
    "        epoch_loss += loss.item()\n",
    "        num_batch += 1\n",
    "    print(f\"Epoch {epoch} : Loss {epoch_loss / num_batch}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5p5_zvu5ECwm",
    "outputId": "61eb161c-fa59-4d83-8383-368c89c44041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForTokenClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDb-iNphECwn"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lH2-QCiPECwp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "train_ner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_eval",
   "language": "python",
   "name": "nlp_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "080b8d2cfa924a499ee5de15d9179320": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_797b347816c3404dbb549bfcacb4a55b",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebf45ae2922a4d5cb74de22823f5423a",
      "value": 435797
     }
    },
    "0b33d2c132a64a3aaf34fa71fc7cb21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb683a2f2164631a40d023696d95aac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10b4645f20ce448c8acef53935d26b03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d95e047c99b40d5b9ee01ab7f4300f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_080b8d2cfa924a499ee5de15d9179320",
       "IPY_MODEL_56cfa0be0d1e4632a9820dd1ecbc7dca"
      ],
      "layout": "IPY_MODEL_0eb683a2f2164631a40d023696d95aac"
     }
    },
    "30d48ba25f504ed691a7db204334a7a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e6c6a620766468bb308e916d78e935f",
      "max": 411,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a587da037ce4b27b76e5ca351638c3e",
      "value": 411
     }
    },
    "3382b33d766a493f890a833c24e76eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30d48ba25f504ed691a7db204334a7a2",
       "IPY_MODEL_cd29ce07bda94c42b876a85f8f9a7bf6"
      ],
      "layout": "IPY_MODEL_5059f3d33b0d40fba908f45480849872"
     }
    },
    "3e9b557179ab417fb8f6ef4f25319d05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4796ec72c743441c92432c168449e84d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47d1c50d45e342dda3048c70d11afe45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8863f4477a66419bbca96267727b90ac",
      "placeholder": "​",
      "style": "IPY_MODEL_4796ec72c743441c92432c168449e84d",
      "value": " 213k/213k [00:01&lt;00:00, 153kB/s]"
     }
    },
    "5059f3d33b0d40fba908f45480849872": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56cfa0be0d1e4632a9820dd1ecbc7dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10b4645f20ce448c8acef53935d26b03",
      "placeholder": "​",
      "style": "IPY_MODEL_0b33d2c132a64a3aaf34fa71fc7cb21a",
      "value": " 436k/436k [00:00&lt;00:00, 756kB/s]"
     }
    },
    "5adb63bca7bd412b8c070e73c66dbd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "753efb968e0d42498fec98add09a64df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "797b347816c3404dbb549bfcacb4a55b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e6c6a620766468bb308e916d78e935f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8863f4477a66419bbca96267727b90ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b0aba7b184d4f68bf81bfaf1c3fe6ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e043b995e714da689e753ef23a11c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f97f95ed508e4650ac2a3a2196147c04",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5adb63bca7bd412b8c070e73c66dbd8c",
      "value": 213450
     }
    },
    "943ba60c985f49538bfa6c76330140e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e043b995e714da689e753ef23a11c6f",
       "IPY_MODEL_47d1c50d45e342dda3048c70d11afe45"
      ],
      "layout": "IPY_MODEL_b01bc4d4e550497c8b75cfc38e2f55e6"
     }
    },
    "9a587da037ce4b27b76e5ca351638c3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9fa47ad0b24a4740b930e3e6006553f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0af086b308e410b9c63eba24cf559bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b582ddba8d9d4c8a819884174e04fe20",
       "IPY_MODEL_b15518e2992d4fa1969608da3d0f2ebd"
      ],
      "layout": "IPY_MODEL_8b0aba7b184d4f68bf81bfaf1c3fe6ac"
     }
    },
    "b01bc4d4e550497c8b75cfc38e2f55e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b15518e2992d4fa1969608da3d0f2ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df72d4c8f06542c7bad9fefa1616dcb6",
      "placeholder": "​",
      "style": "IPY_MODEL_d0cd7e971cd647aeae042ea8cfc289c1",
      "value": " 263M/263M [00:47&lt;00:00, 5.59MB/s]"
     }
    },
    "b582ddba8d9d4c8a819884174e04fe20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e9b557179ab417fb8f6ef4f25319d05",
      "max": 263273408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_753efb968e0d42498fec98add09a64df",
      "value": 263273408
     }
    },
    "bc17fa0fbd5a4749a480f89892b0a6a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd29ce07bda94c42b876a85f8f9a7bf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fa47ad0b24a4740b930e3e6006553f1",
      "placeholder": "​",
      "style": "IPY_MODEL_bc17fa0fbd5a4749a480f89892b0a6a7",
      "value": " 411/411 [00:00&lt;00:00, 1.63kB/s]"
     }
    },
    "d0cd7e971cd647aeae042ea8cfc289c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df72d4c8f06542c7bad9fefa1616dcb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebf45ae2922a4d5cb74de22823f5423a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f97f95ed508e4650ac2a3a2196147c04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
